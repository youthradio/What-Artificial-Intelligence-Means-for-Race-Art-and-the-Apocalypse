[["apocalypse",[{"start":"1900-01-01T08:00:00.000Z","end":"1900-01-01T08:00:26.761Z","startSeconds":0,"endSeconds":26.761,"passage":"I think the apocalypse in some way, has already happened. We're already at the service of automation, and I think the question that always, always, always comes up with automation, is not if automation is good or bad. But who is the person or who is the group of people that are benefitting from automation? ","speaker":"sam","repeate":false},{"start":"1900-01-01T08:00:26.761Z","end":"1900-01-01T08:00:43.810Z","startSeconds":26.761,"endSeconds":43.81,"passage":"I think that too many popular movies have done us a disservice in thinking about what the real risks are. And when I talk about A.I., I am not talking about humanoid robots.","speaker":"rachel","repeate":false},{"start":"1900-01-01T08:00:43.810Z","end":"1900-01-01T08:01:15.090Z","startSeconds":43.81,"endSeconds":75.09,"passage":"And in the United States, we often have this very murky public-corporate partnerships of private corporations selling technology to police or to government entities. One case that really worries me is in Baltimore. During protest of Freddie Gray's death, Baltimore police used facial recognition to identify protesters. And I think that's a very, very chilling application.","speaker":"rachel","repeate":true},{"start":"1900-01-01T08:01:15.090Z","end":"1900-01-01T08:02:09.001Z","startSeconds":75.09,"endSeconds":129.001,"passage":"And there's some, you know, sci fi that's like interesting around A.I. You know, a super sentient, intelligent robot taking over and destroying things. I think that is less likely to happen than us training a model that has a bug or flaw that ends up killing somebody. That's definitely the real world dystopia.","speaker":"deb","repeate":false},{"start":"1900-01-01T08:02:09.001Z","end":"1900-01-01T08:02:23.197Z","startSeconds":129.001,"endSeconds":143.197,"passage":"Young people are growing up online in this world where they're being fed a lot of information from their friends, from their family, from these websites. And it's A.I. that's controlling what they see.","speaker":"deb","repeate":true}]],["raceandbias",[{"start":"1900-01-01T08:00:00.000Z","end":"1900-01-01T08:00:18.000Z","startSeconds":0,"endSeconds":18,"passage":"Non-white people actually don't show up as well in the facial recognition database, which also means that you've developed this technology that is biased in this very obvious way. The computer will literally not know anything that isn't in the dataset that's been presented to it. So that data becomes extremely important.","speaker":"alexis","repeate":false},{"start":"1900-01-01T08:00:19.000Z","end":"1900-01-01T08:00:54.000Z","startSeconds":19,"endSeconds":54,"passage":"There was a study released where we evaluated the commercial facial recognition systems that were deployed. And we said, \"How well does this system work for different intersectional demographics?\" So, how well does it work for darker skinned woman versus lighter skinned woman versus darker skinned men and lighter skinned men? And it figures that there was a 30 percent performance gap between lighter skinned men and darker skinned men, which is insane. For reference, usually you don't deploy a system that's performing at less than 95 percent accuracy. \n","speaker":"deb","repeate":false},{"start":"1900-01-01T08:00:57.605Z","end":"1900-01-01T08:01:25.000Z","startSeconds":57.605,"endSeconds":85,"passage":"The way that these models perform actually changes based off of who you are, and that's super problematic. You know, if you're a darker skinned person, you're actually more at risk of being misclassified. And for certain products that are used by law enforcement, that are used by immigration, that are used in military situations, it becomes a safety risk to be a darker skinned person because you're less likely to be classified properly.","speaker":"deb","repeate":true},{"start":"1900-01-01T08:01:26.000Z","end":"1900-01-01T08:01:57.000Z","startSeconds":86,"endSeconds":117,"passage":"Another example of bias comes from some software that's used in many U.S. courtrooms. It gives people a rating of how likely they are to commit another crime. And it was found that this software has twice as high a false positive rate on black defendants compared to white defendants. So that means it was predicting that people were high risk even though they were not being rearrested. And so this is something that's really impacting people's lives because it was being used in sentencing decisions and bail decisions. ","speaker":"rachel","repeate":false},{"start":"1900-01-01T08:01:58.000Z","end":"1900-01-01T08:02:25.000Z","startSeconds":118,"endSeconds":145,"passage":"I think all data is biased, and to me, some of the most promising work around this is proposals around different ways to make those biases clearer, to include information about how data was collected — who's included who's not — so that people aren't blindsided by these biases.","speaker":"rachel","repeate":true}]],["art",[{"start":"1900-01-01T08:00:00.000Z","end":"1900-01-01T08:00:19.490Z","startSeconds":0,"endSeconds":19.49,"passage":"There's all these kinds of intelligence: the intelligence in our bodies, intelligence that's expressed when we dance or we play sports, or you have a conversation with somebody and you look at them and you go \"that person's probably thinking that.\" No machine can do that. And yet we humans all do that instantly, easily, perfectly.","speaker":"alexis","repeate":false},{"start":"1900-01-01T08:00:19.490Z","end":"1900-01-01T08:00:36.440Z","startSeconds":19.49,"endSeconds":36.44,"passage":"I don't think we'll ever see a truly, beautiful work of art made by a machine. I don't think we'll ever see such a thing as even a neutral or a just machine.","speaker":"sam","repeate":false},{"start":"1900-01-01T08:00:36.440Z","end":"1900-01-01T08:00:49.917Z","startSeconds":36.44,"endSeconds":49.917,"passage":"We think about music and art and we invent things. And it's beautiful. It's awesome. And I think we have an appreciation for art and literature and poetry. And I think that's a very uniquely human thing. ","speaker":"deb","repeate":false},{"start":"1900-01-01T08:00:49.917Z","end":"1900-01-01T08:01:24.700Z","startSeconds":49.917,"endSeconds":84.7,"passage":"There are these interesting projects where you can compose these songs and the A.I. model will sort of pick the next note so you can compose an entire jazz tune through an A.I. system. And I think that it's just super fun and it comes out with these tunes that are super nonsensical musically. A composer wouldn't think of setting things up that way. But you're like, \"Hey, this is kind of a jam. I'm into this.\" So A.I. generated music is definitely on the horizon.","speaker":"deb","repeate":true}]]]